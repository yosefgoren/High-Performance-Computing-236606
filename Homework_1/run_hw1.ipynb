{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HW1 Notebook\n",
    "#### This assignment will introduce you with the Intel DevCloud and with OpenMP basic directives and concepts of parallel computing as part of the OpenMP Common Core. \n",
    "\n",
    "#### Use this notebook to compile your files, submit your jobs to Intel DevCloud nodes and observe/analyze your results.\n",
    "## Submittion instructions\n",
    "- #### Publication Date: 10/11.\n",
    "- #### Submission Date: 4/12.\n",
    "- #### Submittion in groups of up to 2 students (individually or in pairs). \n",
    "- #### Submittion on the course website, in zip format including this directory with the relevant output, specifically: \n",
    "  - the source files.\n",
    "  - this notebook (run_hw1.ipynb) after executing all the cells. \n",
    "  - output files of queued jobs that might be created during the execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fill the name and ID of the submitters:\n",
    "#### Student Name: Yosef Goren Stdudent ID: 211515606\n",
    "\n",
    "**Note:** If you submit in pairs, it is sufficient that only single student submit the assaignment on the course website. \\\n",
    "Remove one line if submitted individually, or keep it empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the Portable Batch System (PBS) on Intel DevCloud\n",
    "\n",
    "Portable Batch System (PBS) is the scheduler that is used on Intel DevCloud to submit jobs on the cluster. \\\n",
    "The next material may help you manage your work on the cloud:\n",
    "- **Quick tutorial for PBS:** https://albertsk.files.wordpress.com/2011/12/pbs.pdf.\n",
    "- **Intel DevCloud Job Submission:** https://devcloud.intel.com/oneapi/documentation/job-submission.\n",
    "- **Intel DevCloud Queue Management:** https://devcloud.intel.com/oneapi/documentation/advanced-queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Know Your Hardware (10 points)\n",
    "### In this section we will get familiar with Intel DevCloud nodes, and learn how to simply submit a job via the PBS scheduler. \n",
    "- The _pbsnodes_ command is used to find out the architectures and features of the compute nodes available to you. The actual output of pbsnodes may be very long if your share of the IntelÂ® DevCloud includes a lot of compute nodes, so you may need to pipe the output. Specifically, it might be interesting to get the list of all the different properties and the number of nodes associated with the property by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pbsnodes | grep \"properties =\" | awk '{print $3}' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The next script is used to print basic hardware specifications of a compute node. Run the next cell to print the content of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print content of check_specifications.sh\n",
    "%pycat check_specifications.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We now submit the script to the Intel Dev Cloud using the _qsub_ command of PBS. \n",
    "When not providing any other parameters, this command allocates the first available node on the cluster for this job. For the next sections of this assignment, we only work with CPU threads (we do not need any further properties like GPU), so for now any node will be fine. Run the following cell. The output will be created in the current directory. Watch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alloc a CPU compute node and see its specifications\n",
    "! chmod 755 check_specifications.sh;\n",
    "! qsub check_specifications.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explain what do you learn from the specs. Focus on:\n",
    "- How many CPU sockets there are in the node?\n",
    "- How many physical cores for each CPU socket?\n",
    "- How many Non-Uniform Memory Access (NUMA) nodes in the system? What does it mean? \n",
    "- What does it mean \"Thread(s) per core\"? (Hint: check in google for \"_Hyper-Threading_\").\n",
    "- What are the cache sizes in the system? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The _q_ script\n",
    "The script file _q_ is used to submit jobs easily via PSB on Intel DevCloud. We will use it from now on. \\\n",
    "When _q_ is used to submit jobs within a Jupityer notebook, then if allocation of resources is enabled within 60 seconds, output will be printed on the notebook itself; otherwise the job will be queded for execution, and the associated output file will be created later in the current directory. \\\n",
    "**Therefore, pay attention that all jobs are completed on notebook or successfully create associated output files before you submit your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Warming-up (10 points)\n",
    "### What are the difference (if any) between the three code snippets? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(A)\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        for(int i=0; i<10000; i++)\n",
    "           Do_Some_Work(i);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(B)\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp for \n",
    "        for(int i=0; i<10000; i++)\n",
    "           Do_Some_Work(i);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(C)\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    {\n",
    "        for(int i=0; i<10000; i++)\n",
    "           Do_Some_Work(i);\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 3: Mandelbrot area (40 points)\n",
    "The mandelbrot set is the set of complex numbers _c_ for which the function _z^2+c_ does not diverge when iterated from z=0. \n",
    "The area of the Mandelbrot set is known to be around 1.506.\n",
    "The serial program in _mandel_serial.c_ loops over a grid of points (5000x5000 points) in the complex plane which contains the Mandelbrot set, and tests each point to see whether it is inside or outside the set.\n",
    "#### In this exercise you will implement various parallel versions of the Mandelbrot program with OpenMP on a CPU node.\n",
    "#### Edit the following files to implement parallelization with CPU threads for the given serial code using OpenMP according to the following requirements:\n",
    "- **_mandel_parallel_critical.c_** - implementation using critical sections for synchronization of a single variable.\n",
    "- **_mandel_parallel_atomic.c_** - implementation using atomic operations for synchronization of a single variable.\n",
    "- **_mandel_parallel_false_sharing.c_** - implementation with global array of variables, each thread updates its own variable, creating false sharing (then a single thread reduce the results). \n",
    "- **_mandel_parallel_padding.c_** - as before, implementation with global array of variables, now using padding to prevent false sharing. \n",
    "- **_mandel_parallel_reduction.c_** - implementation with the reduction clause on a parallel loop construct.\n",
    "\n",
    "##### Hint: In class we saw similar implementations for the Monte Carlo Pi Calculation.\n",
    "##### You are required to test the parallel implementations with a varying number of compute threads. Note that we already made within the files the infrastructure to loop over varying number of threads (to make it easy to you).\n",
    "##### Pay attention you keep the timers wrapping the main loop of calculation in your parallel implementations.\n",
    "\n",
    "#### Then run the following cells, and collect the results.\n",
    "Note that the _.sh._ files include the compilation of the source file for each implementation. In this assaignment we use the _icx_ compiler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd problem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pi_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_serial.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 ../q; chmod 755 mandel_serial.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_serial.sh; else ./run_serial.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pi_parallel_critical.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_parallel_critical.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_parallel_critical.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_critical.sh; else ./run_parallel_critical.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pi_parallel_atomic.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_parallel_atomic.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_parallel_atomic.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_atomic.sh; else ./run_parallel_atomic.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pi_parallel_false_sharing.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_parallel_false_sharing.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_parallel_false_sharing.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_false_sharing.sh; else ./run_parallel_false_sharing.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pi_parallel_padding.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_parallel_padding.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_parallel_padding.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_padding.sh; else ./run_parallel_padding.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pi_parallel_reduction.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat mandel_parallel_reduction.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_parallel_reduction.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_reduction.sh; else ./run_parallel_reduction.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summering the results\n",
    "#### Fill the following table with the execution times (in seconds) according to the number of threads:\n",
    "|  Number of Threads  |      serial       |      critical       |      atomic         |     false sharing   |      padding        |      reduction     |\n",
    "|:-------------------:|:-----------------:|:-------------------:|:-------------------:|:-------------------:|:-------------------:|:------------------:|\n",
    "| 1                   |      fill         |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "| 2                   |       --          |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "| 4                   |       --          |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "| 8                   |       --          |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "| 16                  |       --          |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "| 24                  |       --          |        fill         |        fill         |        fill         |        fill         |        fill        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the results in the following pyplot figure to create a stong scale graph:\n",
    "Note that the values on the graph should be the speedup achieved (relative to a serial computation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "threads = [1,2,4,8,16,24]\n",
    "speedup_critical = [0,1,2,3,4,5] #edit these values\n",
    "speedup_atomic = [1,2,3,4,5,6] #edit these values\n",
    "speedup_false_sharing = [2,3,4,5,6,7] #edit these values\n",
    "speedup_padding = [2,3,4,5,6,7] #edit these values\n",
    "speedup_reduction = [3,4,5,6,7,8] #edit these values\n",
    "\n",
    "plt.plot(threads, speedup_critical, label = \"parallel critical\")\n",
    "plt.plot(threads, speedup_atomic, label = \"parallel atomic\")\n",
    "plt.plot(threads, speedup_false_sharing, label = \"parallel false sharing\")\n",
    "plt.plot(threads, speedup_padding, label = \"parallel padding\")\n",
    "plt.plot(threads, speedup_reduction, label = \"parallel reduction\")\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Number of Threads')\n",
    "# naming the y axis\n",
    "plt.ylabel('Speedup')\n",
    "# giving a title to my graph\n",
    "plt.title('Speedup of the various parallel implementations of Mandelbrot set calculation with OpenMP threading')\n",
    "plt.grid()\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the results\n",
    "Try to explain the results, by comparing the results of different implementations."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 4: nowait clause (10 points)\n",
    "**The nowait clause is used to avoid the implied barrier at the end of a loop construct, when you have multiple independent loops within a parallel region.** \\\n",
    "For each following code snippet, we added OpenMP parallelization using the nowait clause to a given code section. \n",
    "We assume that a,b,y and z point to different pre-allocated arrays (each of size n). \\\n",
    "**For each code snippet, decide whether the parallel code is correct (always brings to the same result as in a serial execution), and explain your decision.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include <math.h>\n",
    "void nowait_example_1(int n, float *a, float *b, float *y, float *z)\n",
    "{\n",
    "    int i;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp for nowait\n",
    "        for (i=0; i<n-1; i++)\n",
    "            b[i] = (a[i] + a[i+1]) / 2.0;\n",
    "            \n",
    "        #pragma omp for nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            y[i] = sqrt(z[i]);  \n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer for nowait_example_1 here ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include <math.h>\n",
    "void nowait_example_2(int n, float *a, float *b, float *y, float *z)\n",
    "{\n",
    "    int i;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp for schedule(static) nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            b[i] = a[i] / 2.0;\n",
    "            \n",
    "        #pragma omp for schedule(static) nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            y[i] = sqrt(b[i]);  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer for nowait_example_2 here ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include <math.h>\n",
    "void nowait_example_2(int n, float *a, float *b, float *y, float *z)\n",
    "{\n",
    "    int i;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp for schedule(dynamic, 8) nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            b[i] = a[i] / 2.0;\n",
    "            \n",
    "        #pragma omp for schedule(dynamic,8) nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            y[i] = sqrt(b[i]);  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer for nowait_example_3 here ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include <math.h>\n",
    "void nowait_example_4(int n, float *a, float *b, float *y, float *z)\n",
    "{\n",
    "    int i;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp single nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            b[i] = a[i] / 2.0;        \n",
    "            \n",
    "        #pragma omp single nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            y[i] = sqrt(b[i]);  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer for nowait_example_4 here ..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include <math.h>\n",
    "void nowait_example_5(int n, float *a, float *b, float *y, float *z)\n",
    "{\n",
    "    int i;\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp master nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            b[i] = a[i] / 2.0;        \n",
    "            \n",
    "        #pragma omp master nowait\n",
    "        for (i=0; i<n; i++)\n",
    "            y[i] = sqrt(b[i]);  \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer for nowait_example_5 here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Count Prime Numbers (30 points)\n",
    "**The schedule clause is used to provide more control over how iterations of a worksharing-loop construct are scheduled onto the threads, usually to balance the workload across threads. It supports both static and dynamic scheduling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../problem5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following serial code counts the amount of prime numbers up to a given limit, by checking for each integer whther it is prime or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat prime_parallel_schedule.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this problem you are required to add parallelization to the main loop of the problem, **using the reduction and schedule clauses**. \\\n",
    "The main focus in your solution will be on choosing the best schedule method (default, static, dynamic, etc) along with the optimized chunk size for a given CPU node on Intel DevCloud. \n",
    "#### Fill the following table with run times (in seconds) for each schedule you examine and for different numbers of threads. Then report what is the optimal schedule method you found and explain your observation. Fill free to add/edit lines in order to tune the parameters, finding the best option you can.\n",
    "\n",
    "|  schedule           |      2 threads    |      4 threads      |      8 threads      |  \n",
    "|:-------------------:|:-----------------:|:-------------------:|:-------------------:|\n",
    "| default             |      fill         |        fill         |        fill         |\n",
    "| static              |       fill        |        fill         |        fill         |\n",
    "| static,4            |       fill        |        fill         |        fill         |\n",
    "| dynamic,8           |       fill        |        fill         |        fill         |\n",
    "| guided              |       fill        |        fill         |        fill         |\n",
    "| .                   |       fill        |        fill         |        fill         |\n",
    "| .                   |       fill        |        fill         |        fill         |\n",
    "| .                   |       fill        |        fill         |        fill         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use _prime_parallel.c_ to edit your parallel implementation. The next cell will help you to execute every time you examine a new schedule option. When you finish, keep the file _prime_parallel.c_ with the optimal schedule you found and execute again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat prime_parallel_schedule.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 ../q; chmod 755 run_parallel_schedule.sh;if [ -x \"$(command -v qsub)\" ]; then ./../q run_parallel_schedule.sh; else ./run_parallel_schedule.sh; fi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Edit your answer here. What is the optimal scheduling method you found? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intel VTune\n",
    "**Now you will get experienced with Intel VTune, to analyze the load balancing of your prime numbers program.** \\\n",
    "According to the table above, find one good scheduling method and one bad scheduling method. Use VTune to show the good/bad load balancing between all the threads for both executions respectively. \\\n",
    "Upload a printscreen of the threading information from VTune. Upload both images in the current directory (problem5) with the following names respectively: \\\n",
    "_vtune_good_load_balancing.png_ \\\n",
    "_vtune_bad_load_balancing.png_ \\\n",
    "You can use the _upload_ button in JupyterLab to easily upload the images. \n",
    "Then run both cells to show the images on the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='vtune_good_load_balancing.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='vtune_bad_load_balancing.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2022.3)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
